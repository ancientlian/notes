# start 与 run 区别

1. start（）方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可
以直接继续执行下面的代码。
2. 通过调用 Thread 类的 start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。
3. 方法 run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运行
run 函数当中的代码。 Run 方法运行结束， 此线程终止。然后 CPU 再调度其它线程。

# 后台线程 守护线程

1. 定义：守护线程--也称“服务线程”，他是后台线程，它有一个特性，即为用户线程提供公共服务，
在没有用户线程可服务时会自动离开。
2. 优先级：守护线程的优先级**比较低**，用于为系统中的其它对象和线程提供服务。
3. 设置：通过 `setDaemon(true)`来设置线程为“守护线程”；将一个用户线程设置为守护线程的方式是
在 线程对象创建 之前 用线程对象的 `setDaemon` 方法。
4. 在 Daemon 线程中产生的新线程也是 Daemon 的。
5. 线程则是 JVM 级别的，以 Tomcat 为例，如果你在 Web 应用中启动一个线程，这个线程的生命周
期并不会和 Web 应用程序保持同步。也就是说，即使你停止了 Web 应用，这个线程依旧是活跃的。
6. example: **垃圾回收线程**就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread, 程
序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是 JVM 上仅剩的线程时，垃
圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统中的可回收资
源。
7. 生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地
执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是**依赖于系统****，与**
**系统“同生共死”**。当 JVM 中所有的线程都是守护线程的时候，JVM 就可以退出了；如果还有一个或
以上的非守护线程则 JVM 不会退出。



# 乐观锁（非阻塞同步锁）

乐观锁是一种乐观思想，即**认为读多写少**，遇到并发写的可能性低，每次去拿数据的时候都认为别人不
会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写
时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复
读-比较-写的操作。

java 中的乐观锁基本都是通过 **CAS 操作**实现的，CAS 是一种更新的原子操作，比较当前值跟传入值是否
一样，一样则更新，否则失败。

非阻塞锁是不可重入的，否则会造成死锁。

# 悲观锁（互斥同步锁）

悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修
改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。 java中的悲
观锁就是`Synchronized`,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观
锁，如 `RetreenLock`。



# 自旋锁

自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不
需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释
放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。

线程自旋是需要消耗 cup 的，说白了就是让 cup 在做无用功，如果一直获取不到锁，那线程也不能一直
占用 cup 自旋做无用功，所以**需要设定一个自旋等待的最大时间**。

如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最
大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。
自旋锁的优缺点
自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大
幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次
上下文切换！
但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁
了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量线程在竞争一个
锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cup 的线程又
不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁；
自旋锁时间阈值（1.6引入了适应性自旋锁）
自旋锁的目的是为了占着 CPU 的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行
时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的
性能。因此自旋的周期选的额外重要！





# 内存泄漏

## 怎样阻止内存泄露

1.使用List、Map等集合时，在使用完成后赋值为null
2.使用大对象时，在用完后赋值为null
3.目前已知的jdk1.6的substring()方法会导致内存泄露
4.避免一些死循环等重复创建或对集合添加元素，撑爆内存
5.简洁数据结构、少用静态集合等
6.及时的关闭打开的文件，socket句柄等
7.多关注事件监听(listeners)和回调(callbacks)，比如注册了一个listener，当它不再被使用的时候，忘
了注销该listener，可能就会产生内存泄露







# 线程池的处理流程

提交一个任务到线程池中，线程池的处理流程如下：
1、判断**线程池里的核心线程**是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创
建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。
2、线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如
果工作队列满了，则进入下个流程。
3、判断**线程池里的线程**是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已
经满了，则交给饱和策略来处理这个任务。



刚开始都是在创建新的线程，达到核心线程数量5个后，新的任务进来后不再创建新的线程，而是将任
务加入工作队列，任务队列到达上线5个后，新的任务又会创建新的普通线程，直到达到线程池最大的线
程数量10个，后面的任务则根据配置的饱和策略来处理。我们这里没有具体配置，使用的是默认的配置
AbortPolicy:直接抛出异常。



# RejetedExecutionHandler：饱和策略

当队列和线程池都满了，说明线程池处于饱和状态，那么必须对新提交的任务采用一种特殊的策略来进
行处理。这个策略默认配置是AbortPolicy，表示无法处理新的任务而抛出异常。JAVA提供了4中策略：
1、AbortPolicy：直接抛出异常
2、CallerRunsPolicy：只用调用所在的线程运行任务
3、DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
4、DiscardPolicy：不处理，丢弃掉。

# 任务拒绝类型 RejetedExecutionHandler：饱和策略

## ThreadPoolExecutor.AbortPolicy:

当线程池中的数量等于最大线程数时抛 java.util.concurrent.RejectedExecutionException 异常，涉及到该异常的任务也不会被执行，线程池默认的拒绝策略就是该策略。

```java
/**
         * Always throws RejectedExecutionException.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         * @throws RejectedExecutionException always
         */
public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
    throw new RejectedExecutionException("Task " + r.toString() +
                                         " rejected from " +
                                         e.toString());
}
```

使用该策略时在饱和时会抛出RejectedExecutionException（继承自RuntimeException），调用者可捕获该异常自行处理。

## ThreadPoolExecutor.DiscardPolicy():

当线程池中的数量等于最大线程数时,默默丢弃不能执行的新加任务，不报任何异常。

```java
        /**
         * Does nothing, which has the effect of discarding task r.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
        }
```

如代码所示，不做任何处理直接抛弃任务

## ThreadPoolExecutor.CallerRunsPolicy():调用者运行

当线程池中的数量等于最大线程数时，重试添加当前的任务；它会自动重复调用execute()方法。

```java
        /**
         * Executes task r in the caller's thread, unless the executor
         * has been shut down, in which case the task is discarded.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                r.run();
            }
        }
```

既不抛弃任务也不抛出异常，直接运行任务的run方法，换言之将任务回退给调用者来直接运行。使用
该策略时线程池饱和后将由调用线程池的主线程自己来执行任务，因此在执行任务的这段时间里主线程
无法再提交新任务，从而使线程池中工作线程有时间将正在处理的任务处理完成。

## ThreadPoolExecutor.DiscardOldestPolicy():

当线程池中的数量等于最大线程数时,抛弃线程池中工作队列头部的任务(即等待时间最久的任务)，并执行新传入的任务

```java
        /**
         * Obtains and ignores the next task that the executor
         * would otherwise execute, if one is immediately available,
         * and then retries execution of task r, unless the executor
         * is shut down, in which case task r is instead discarded.
         *
         * @param r the runnable task requested to be executed
         * @param e the executor attempting to execute this task
         */
        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                e.getQueue().poll();
                e.execute(r);
            }
        }
```

如代码，先将阻塞队列中的头元素出队抛弃，再尝试提交任务。如果此时阻塞队列使用PriorityBlockingQueue优先级队列，将会导致优先级最高的任务被抛弃，因此不建议将该种策略配合优先级队列使用。



# Executors可以创建3种类型的ThreadPoolExecutor



## a、SingleThreadExecutor：单线程线程池

```java
ExecutorService threadPool = Executors.newSingleThreadExecutor();
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService(
        new ThreadPoolExecutor(1, 1,
    	0L, TimeUnit.MILLISECONDS,
    	new LinkedBlockingQueue<Runnable>()));
}
```

我们从源码来看可以知道，单线程线程池的创建也是通过ThreadPoolExecutor，里面的核心线程数和线程数都是1，并且工作队列使用的是无界队列。由于是单线程工作，每次只能处理一个任务，所以后面所有的任务都被阻塞在工作队列中，只能一个个任务执行。

## b、FixedThreadExecutor：固定大小线程池

```java
ExecutorService threadPool = Executors.newFixedThreadPool(5);
public static ExecutorService newFixedThreadPool(int nThreads) {
	return new ThreadPoolExecutor(
        	nThreads, nThreads,
			0L, TimeUnit.MILLISECONDS,
			new LinkedBlockingQueue<Runnable>());
}
```

这个与单线程类似，只是创建了固定大小的线程数量。使用固定大小的线程池并使用**无限大的队列**

## c、CachedThreadPool：无界线程池

```java
    ExecutorService threadPool = Executors.newCachedThreadPool();
    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(
            	0, Integer.MAX_VALUE,
                60L, TimeUnit.SECONDS,
                new SynchronousQueue<Runnable>());
    }
```

无界线程池意味着没有工作队列，任务**进来就执行，线程数量不够就创建，与前面两个的区别是：空闲的线程会被回收掉，空闲的时间是60s。**这个适用于执行很多短期异步的小程序或者负载较轻的服务器。

在newCachedThreadPool中如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新 建线程。 

初看该构造函数时我有这样的疑惑：核心线程池为0，那按照前面所讲的线程池策略新任务来临时无法进 入核心线程池，只能进入 SynchronousQueue中进行等待，而SynchronousQueue的大小为1，那岂不 是第一个任务到达时只能等待在队列中，直到第二个任务到达发现无法进入队列才能创建第一个线程？ 这个问题的答案在上面讲SynchronousQueue时其实已经给出了，要将一个元素放入 SynchronousQueue中，必须有另一个线程正在等待接收这个元素。因此即便SynchronousQueue一开 始为空且大小为1，第一个任务也无法放入其中，因为没有线程在等待从SynchronousQueue中取走元 素。因此第一个任务到达时便会创建一个新线程执行该任务。 

这里引申出一个小技巧：有时我们可能希望线程池在没有任务的情况下销毁所有的线程，既设置线程池 核心大小为0，但又不想使用SynchronousQueue而是想使用有界的等待队列。显然，不进行任何特殊 设置的话这样的用法会发生奇怪的行为：直到等待队列被填满才会有新线程被创建，任务才开始执行。 这并不是我们希望看到的，此时可通过allowCoreThreadTimeOut使等待队列中的元素出队被调用执 行，详细原理和使用将会在后续博客中阐述。





## newWorkStealingPool创建一个拥有多个任务队列（以便减少连接数）的线程池。

```java

    /**
     * Creates a work-stealing thread pool using all
     * {@link Runtime#availableProcessors available processors}
     * as its target parallelism level.
     * @return the newly created thread pool
     * @see #newWorkStealingPool(int)
     * @since 1.8
     */
    public static ExecutorService newWorkStealingPool() {
        return new ForkJoinPool
            (Runtime.getRuntime().availableProcessors(),
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
```

返回的ForkJoinPool从jdk1.7开始引进，个人感觉类似于mapreduce的思想。



# Executors可以创建2种类型的ScheduledThreadPoolExecutor

## newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。

```java
    /**
     * Creates a thread pool that can schedule commands to run after a
     * given delay, or to execute periodically.
     * @param corePoolSize the number of threads to keep in the pool,
     * even if they are idle
     * @return a newly created scheduled thread pool
     * @throws IllegalArgumentException if {@code corePoolSize < 0}
     */
    public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
        return new ScheduledThreadPoolExecutor(corePoolSize);
    }
```

```java
    /**
     * Creates a new {@code ScheduledThreadPoolExecutor} with the
     * given core pool size.
     *
     * @param corePoolSize the number of threads to keep in the pool, even
     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set
     * @throws IllegalArgumentException if {@code corePoolSize < 0}
     */
    public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue());
    }
```



`ScheduledThreadPoolExecutor`的父类即`ThreadPoolExecutor`，因此这里各参数含义和上面一样。值得关心的是DelayedWorkQueue这个阻塞对列，在上面没有介绍，它作为静态内部类就在ScheduledThreadPoolExecutor中进行了实现。具体分析讲会在后续博客中给出，在这里只进行简单说明：**DelayedWorkQueue是一个无界队列，它能按一定的顺序对工作队列中的元素进行排列。因此这里设置的最大线程数 Integer.MAX_VALUE没有任何意义。**关于ScheduledThreadPoolExecutor的具体使用将会在后续quartz的周期性任务实现原理中进行进一步分析。



## SingleThreadScheduledExecutor创建单个线程的

```java
public static ScheduledExecutorService newSingleThreadScheduledExecutor()
public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory)
```

SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺 序地执行各个任务的应用场景。



# 创建线程池的几种方式

`ThreadPoolExecutor`、`ScheduledThreadPoolExecutor`、`ForkJoinPool`

![image-20211222234110099](F:\WorkSpace\Lian\notes\面试\多线程面试.assets\image-20211222234110099.png)





# Java 多线程安全机制

我们都知道java的内存模型中有主内存和线程的工作内存之分，主内存上存放的是线程共享的变量（实
例字段，静态字段和构成数组的元素），线程的工作内存是线程私有的空间，存放的是线程私有的变量
（方法参数与局部变量）。线程在工作的时候如果要操作主内存上的共享变量，为了获得更好的执行性
能并不是直接去修改主内存而是会在线程私有的工作内存中创建一份变量的拷贝（缓存），在工作内存
上对变量的拷贝修改之后再把修改的值刷回到主内存的变量中去，JVM提供了8中原子操作来完成这一过
程：lock, unlock, read, load, use, assign, store, write。深入理解java虚拟机-jvm最高特性与实践这本
书中有一个图很好的表示了线程，主内存和工作内存之间的关系：

![image-20211223224417818](F:\WorkSpace\Lian\notes\面试\多线程面试.assets\image-20211223224417818.png)

如果只有一个线程当然不会有什么问题，但是如果有多个线程同时在操作主内存中的变量，因为8种操作
的非连续性和线程抢占cpu执行的机制就会带来冲突的问题，也就是多线程的安全问题。线程安全的定
义就是：如果线程执行过程中不会产生共享资源的冲突就是线程安全的。

## 1.互斥同步锁（悲观锁）

1）Synchorized
2）ReentrantLock

## 2.非阻塞同步锁

1) 原子类（CAS）

## 3.无同步方案

1）可重入代码
在执行的任何时刻都可以中断-重入执行而不会产生冲突。特点就是不会依赖堆上的共享资源

2）ThreadLocal/Volaitile
线程本地的变量，每个线程获取一份共享变量的拷贝，单独进行处理。

3）线程本地存储
如果一个共享资源一定要被多线程共享，可以尽量让一个线程完成所有的处理操作，比如生产者消费者
模式中，一般会让一个消费者完成对队列上资源的消费。典型的应用是基于请求-应答模式的web服务器
的设计





# 如何合理配置线程池的大小

线程池究竟设置多大要看你的线程池执行的什么任务了，CPU密集型、IO密集型、混合型，任 务类型不
同，设置的方式也不一样。
任务一般分为：CPU密集型、IO密集型、混合型，对于不同类型的任务需要分配不同大小的线 程池。

## 1）CPU密集型

尽量使用较小的线程池，一般Cpu核心数+1

## 2）IO密集型

方法一：可以使用较大的线程池，一般CPU核心数 * 2

方法二：（线程等待时间与线程CPU时间之比 + 1）* CPU数目

方法二：线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。
下面举个例子：
比如平均每个线程CPU运行时间为0.5s，而线程等待时间（非CPU运行时间，比如IO）为1.5s，CPU核
心数为8，那么根据上面这个公式估算得到：((0.5+1.5)/0.5)\*8=32。这个公式进一步转化为：
最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）\* CPU数目

## 3）混合型 

可以将任务分为CPU密集型和IO密集型，然后分别使用不同的线程池去处理，按情况而定







# volatile、ThreadLocal的使用场景和原理



## volatile原理

volatile变量进行写操作时，JVM 会向处理器发送一条 Lock 前缀的指令，将这个变量所在缓 存行的数据
写会到系统内存。
Lock 前缀指令实际上相当于一个内存屏障（也成内存栅栏），它确保指令重排序时不会把其 后面的指
令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内 存屏障这句指令
时，在它前面的操作已经全部完成。

## volatile的适用场景;正确使用 volatile 的模式

### 1）状态标志, 如：初始化或请求停机

也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。

```java
    volatile boolean shutdownRequested;
	...
    public void shutdown() {
        shutdownRequested = true;
    }

    public void doWork() {
        while (!shutdownRequested) {
            // do stuff
        }
    }
```

线程1执行doWork()的过程中，可能有另外的线程2调用了shutdown，所以boolean变量必须是volatile。

而如果使用 synchronized 块编写循环要比使用 volatile 状态标志编写麻烦很多。由于 volatile 简化了编码，并且状态标志并不依赖于程序内任何其他状态，因此此处非常适合使用 volatile。

这种类型的状态标记的一个公共特性是：通常只有一种状态转换； `shutdownRequested` 标志从 `false`转换为` true` ，然后程序停止。这种模式可以扩展到来回转换的状态标志，但是只有在转换周期不被察觉的情况下才能扩展（从` false `到` true `，再转换到 `false `）。此外，还需要某些原子状态转换机制，例如原子变量。



### 2）一次性安全发布（one-time safe publication），如：单列模式

在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。

这就是造成著名的双重检查锁定（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象。

```java
//注意volatile！！！！！！！！！！！！！！！！！
private volatile static Singleton instance;

public static Singleton getInstance() {
    //第一次null检查
    if (instance == null) {
        synchronized (Singleton.class) { //1
            //第二次null检查
            if (instance == null) { //2
                instance = new Singleton();//3
            }
        }
    }
    return instance;
}
```

==如果不用volatile，则因为内存模型允许所谓的“无序写入”，可能导致失败。——某个线程可能会获得一个未完全初始化的实例。==

考察上述代码中的 //3 行。此行代码创建了一个 Singleton 对象并初始化变量 instance 来引用此对象。

这行代码的问题是：**在Singleton 构造函数体执行之前，变量instance 可能成为非 null 的！**什么？这一说法可能让您始料未及，但事实确实如此。
在解释这个现象如何发生前，请先暂时接受这一事实，我们先来考察一下双重检查锁定是如何被破坏的。假设上述代码执行以下事件序列：

1. 线程 1 进入 `getInstance() `方法。
2. 由于 instance 为 null，线程 1 在 //1 处进入`synchronized `块。
3. 线程 1 前进到 //3 处，但在构造函数执行之前，使实例成为非null。
4. 线程 1 被线程 2 预占。
5. 线程 2 检查实例是否为 null。因为实例不为 null，线程 2 将instance 引用返回，返回一个**构造完整但部分初始化了**的Singleton 对象。
6. 线程 2 被线程 1 预占。
7. 线程 1 通过运行 Singleton 对象的构造函数并将引用返回给它，来完成对该对象的初始化。



清单 3. 将 volatile 变量用于一次性安全发布

```java
public class BackgroundFloobleLoader {
    public volatile Flooble theFlooble;

    public void initInBackground() {
        // do lots of stuff
        theFlooble = new Flooble(); // this is the only write to theFlooble
    }
}

public class SomeOtherClass {
    public void doWork() {
        while (true) {
            // do some stuff...
            // use the Flooble, but only if it is ready
            if (floobleLoader.theFlooble != null)
                doSomething(floobleLoader.theFlooble);
        }
    }
}
```

如果 `theFlooble `引用不是 `volatile `类型， `doWork() `中的代码在解除对 `theFlooble `的引用时，将会得到一个不完全构造的` Flooble `。

该模式的一个必要条件是：**被发布的对象必须是线程安全的，或者是有效的不可变对象**（有效不可变意味着对象的状态在发布之后永远不会被修改）。

volatile 类型的引用可以确保对象的发布形式的可见性，但是如果对象的状态在发布后将发生更改，那么就需要额外的同步。



### 3）独立观察（independent observation），如：定期更新某个值

安全使用 volatile 的另一种简单模式是：定期 “发布” 观察结果供程序内部使用。

【例如】假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的
volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。

使用该模式的另一种应用程序就是收集程序的统计信息。

【例】如下代码展示了身份验证机制如何记忆最近一次登录的用户的名字。将反复使用 lastUser 引用来发布值，以供程序的其他部分使用。

```java
public class UserManager {
    public volatile String lastUser; //发布的信息

    public boolean authenticate(String user, String password) {
        boolean valid = passwordIsValid(user, password);
        if (valid) {
            User u = new User();
            activeUsers.add(u);
            lastUser = user;
        }
        return valid;
    }
}
```

该模式是前面模式的扩展；将某个值发布以在程序内的其他地方使用，但是与一次性事件的发布不同，这是一系列独立事件。这个模式要求被发布的值是有效不可变的 —— 即值的状态在发布后不会更改。使用该值的代码需要清楚该值可能随时发生变化。



### 4）“volatile bean” 模式

volatile bean 模式的基本原理是：很多框架为易变数据的持有者（例如 HttpSession ）提供了容器，但是放入这些容器中的对象必须是线程安全的。

在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通——即不包含约束！

```java
@ThreadSafe
public class Person {
    private volatile String firstName;
    private volatile String lastName;
    private volatile int age;

    public String getFirstName() {
        return firstName;
    }

    public String getLastName() {
        return lastName;
    }

    public int getAge() {
        return age;
    }

    public void setFirstName(String firstName) {
        this.firstName = firstName;
    }

    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    public void setAge(int age) {
        this.age = age;
    }
}
```



### 5）开销较低的“读－写锁”策略，如：计数器

目前为止，您应该了解了 volatile 的功能还不足以实现计数器。因为 `++x `实际上是三种操作（读、添加、存储）的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。

如果读操作远远超过写操作，您可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。

如下显示的线程安全的计数器，使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及volatile 读操作，这通常要优于一个无竞争的锁获取的开销。

```java
@ThreadSafe
public class CheesyCounter {
    // Employs the cheap read-write lock trick
    // All mutative operations MUST be done with the 'this' lock held
    @GuardedBy("this")
    private volatile int value;

    //读操作，没有synchronized，提高性能
    public int getValue() {
        return value;
    }

    //写操作，必须synchronized。因为x++不是原子操作
    public synchronized int increment() {
        return value++;
    }
```

使用锁进行所有变化的操作，使用 volatile 进行只读操作。

其中，锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作

> 之所以将这种技术称之为 “开销较低的读－写锁” 是因为您使用了不同的同步机制进行读写操作。因为本
> 例中的写操作违反了使用 volatile 的第一个条件，因此不能使用 volatile 安全地实现计数器 —— 您必须
> 使用锁。然而，您可以在读操作中使用 volatile 确保当前值的可见性，因此可以使用锁进行所有变化的
> 操作，使用 volatile 进行只读操作。其中，锁一次只允许一个线程访问值，volatile 允许多个线程执行读
> 操作，因此当使用 volatile 保证读代码路径时，要比使用锁执行全部代码路径获得更高的共享度 —— 就
> 像读－写操作一样。然而，要随时牢记这种模式的弱点：如果超越了该模式的最基本应用，结合这两个
> 竞争的同步机制将变得非常困难。
>
> 

## ThreadLocal原理

ThreadLocal是用来维护本线程的变量的，并不能解决共享变量的并发问题。ThreadLocal是 各线程将
值存入该线程的map中，以ThreadLocal自身作为key，需要用时获得的是该线程之前 存入的值。如果
存入的是共享变量，那取出的也是共享变量，并发问题还是存在的。

## ThreadLocal的适用场景

场景：数据库连接、Session管理



# volatile 变量使用指南

Java 语言中的 volatile 变量可以被看作是一种 “程度较轻的 synchronized ”；与 synchronized 块相比，volatile 变量所需的编码较少，并且运行时开销也较少，但是它所能实现的功能也仅是`synchronized `的一部分。

==Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。==这就是说线程能够自动发现volatile 变量的最新值。Volatile 变量可用于提供线程安全，但是只能应用于非常有限的一组用例：多个变量之间或者某个变量的当前值与修改后值之间没有约束。因此，单独使用 volatile 还不足以实现计数器、互斥锁或任何具有与多个变量相关的不变式（Invariants）的类（例如 “start <=end”）。



# 正确使用 volatile 变量的条件

- 对变量的写操作不依赖于当前值。
- 该变量没有包含在具有其他变量的不变式中。

实际上，这些条件表明，可以被写入 volatile 变量的这些有效值**独立于任何程序的状态，包括变量的当前状态**。

清单 1 显示了一个非线程安全的数值范围类。它包含了一个不变式 —— 下界总是小于或等于上界。

清单 1. 非线程安全的数值范围类

```java
    @NotThreadSafe
    public class NumberRange {
        private int lower, upper;

        public int getLower() {
            return lower;
        }

        public int getUpper() {
            return upper;
        }

        public void setLower(int value) {
            if (value > upper)
                throw new IllegalArgumentException(...);
            lower = value;
        }

        public void setUpper(int value) {
            if (value < lower)
                throw new IllegalArgumentException(...);
            upper = value;
        }
    }
```

# volatile性能考虑

使用 volatile 变量的主要原因是其**简易性**：在某些情形下，使用 volatile 变量要比使用相应的锁简单得多。

使用 volatile 变量次要原因是其**性能**：某些情况下，volatile 变量同步机制的性能要优于锁。



# ThreadLocal什么时候会出现OOM的情况？为什么？

留空



# synchronized、volatile区别

1) volatile主要应用在多个线程对实例变量更改的场合，**刷新主内存共享变量的值从而使得各个线程可以获得最新的值**，线程读取变量的值需要从主存中读取；**synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住**。另外，synchronized还会创建一个内存屏障，内存屏障指令保证了所有CPU操作结果都会直接刷到主存中（即释放锁前），从而保证了操作的内存可见性，同时也使得先获得这个锁的线程的所有操作
2) volatile仅能使用在**变量级别**；synchronized则可以使用在**变量、方法、和类级别**的。 v**olatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞**，比如多个线程争抢 synchronized锁对象时，会出现阻塞。
3) volatile仅能实现变量的修改可见性，**不能保证原子性**；而**synchronized则可以保证变量的修改可见性和原子性**，因为线程获得锁才能进入临界区，从而保证临界区中的所有语句全部得到执行。
4) volatile标记的变量**不会被编译器优化**，可以禁止进行指令重排；synchronized标记的变量**可以被编译器优化**。

> 指令重排：处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证各个语句的执行顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。
>
> JMM处理过程：JMM是通过禁止特定类型的编译器重排序和处理器重排序来为程序员提供一致的内存可
> 见性保证。例如A线程具体什么时候刷新共享数据到主内存是不确定的，假设我们使用了同步原语
> (synchronized，volatile和final),那么刷新的时间是确定的。





# 比较synchronized和volatile三条性质：

## 原子性

原子性是指一个操作是不可中断的，要么全部执行成功要么全部执行失败，有着“同生共死”的感觉。

java内存模
型中定义了8中操作都是原子的，不可再分的。

1. lock(锁定)：作用于主内存中的变量，它把一个变量标识为一个线程独占的状态；
2. unlock(解锁)：作用于主内存中的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
3. read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便后面的load动作使用；
4. load（载入）：作用于工作内存中的变量，它把read操作从主内存中得到的变量值放入工作内存中的变量副本
5. use（使用）：作用于工作内存中的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作；
6. assign（赋值）：作用于工作内存中的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作；
7. store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送给主内存中以便随后的write操作使用；
8. write（操作）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。

**java内存模型只是要求上述两个操作是顺序执行的并不是连续执行的。**也就是说read和load之间可以插入其他指令，store和writer可以插入其他指令。比如对主内存中的a,b进行访问就可以出现这样的操作顺序：read a,read b, load b,load a。

由原子性变量操作read,load,use,assign,store,write，可以**大致认为基本数据类型的访问读写具备原子性**（例外就是long和double的非原子性协定）

> long和double的非原子性协定（Nonatomic Treatment of double and long Variable）
> Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有原子性，但是对于64位的数据类型（double、long）定义了相对宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次的32位操作来进行，即允许虚拟机可以不保证64位数据类型的load、store、read和write操作的原子性。
>
> 非原子性协定可能导致的问题
> 如果有多个线程共享一个未申明为volatile的long或double类型的变量，并且同时对其进行读取和修改操作，就有可能会有线程读取到"半个变量"的数值或者是一半正确一半错误的失效数据。
>
> 在实际应用中的解决
> 因为上述可能造成的问题，势必在对long和double类型变量操作时要加上volatile关键字，实际上如下：
>
> 1、64位的java虚拟机不存在这个问题，可以操作64位的数据
>
> 2、目前商用JVM基本上都会将64位数据的操作作为原子操作实现
>
> 所以我们编写代码时一般不需要将long和double变量专门申明为volatile
> ------------------------------------------------
> 版权声明：本文为CSDN博主「Wonder丶丶丶」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/WZH577/article/details/107674064

### synchronized

上面一共有八条原子操作，其中六条可以满足基本数据类型的访问读写具备原子性，还剩下lock和unlock两条原子操作。如果我们需要更大范围的原子性操作就可以使用lock和unlock原子操作。尽管jvm没有把lock和unlock开放给我们使用，但jvm以更高层次的指令monitorenter和monitorexit指令开放给我们使用，反应到java代码中就是---synchronized关键字，也就是说synchronized满足原子性。

### volatile

我们先来看这样一个例子：

```java
public class VolatileExample {
    private static volatile int counter = 0;

    public static void main(String[] args) {
        for (int i = 0; i < 10; i++) {
            Thread thread = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 10000; i++)
                        counter++;
                }
            });
            thread.start();
        }
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(counter);
    }
}
```

开启10个线程，每个线程都自加10000次，如果不出现线程安全的问题最终的结果应该就是：10*10000= 100000;可是运行多次都是小于100000的结果，问题在于 volatile并不能保证原子性，在前面说过counter++这并不是一个原子操作，包含了三个步骤：1.读取变量counter的值；2.对counter加一；3.将新值赋值给变量counter。如果线程A读取counter到工作内存后，其他线程对这个值已经做了自增操作后，那么线程A的这个值自然而然就是一个过期的值，因此，总结果必然会是小于100000的。如果让volatile保证原子性，必须符合以下两条规则：
1. 运算结果并不依赖于变量的当前值，或者能够确保只有一个线程修改变量的值；
2. 变量不需要与其他的状态变量共同参与不变约束



## 可见性

可见性是指当一个线程修改了共享变量后，其他线程能够立即得知这个修改。

通过之前对synchronzed内存语义进行了分析，当线程获取锁时会从主内存中获取共享变量的最新值，释放锁的时候会将共享变量同步到主内存中。

从而，synchronized具有可见性。同样的在volatile分析中，会通过在指令中添加lock指令，以实现内存可见性。因此, volatile具有可见性

## 有序性

### synchronized

synchronized语义表示锁在同一时刻只能由一个线程进行获取，当锁被占用后，其他线程只能等待。因此，synchronized语义就要求线程在访问读写共享变量时只能“串行”执行，因此synchronized具有有序性。

### volatile

在java内存模型中说过，为了性能优化，编译器和处理器会进行指令重排序；也就是说java程序天然的有序性可以总结为：如果在本线程内观察，所有的操作都是有序的；如果在一个线程观察另一个线程，所有的操作都是无序的。在单例模式的实现上有一种双重检验锁定的方式（Double-checkedLocking）。代码如下：

```java
    public class Singleton {
        private Singleton() {
        }

        private volatile static Singleton instance;

        public Singleton getInstance() {
            if (instance == null) {
                synchronized (Singleton.class) {
                    if (instance == null) {
                        instance = new Singleton();
                    }
                }
            }
            return instance;
        }
    }
```

这里为什么要加volatile了？我们先来分析一下不加volatile的情况，有问题的语句是这条：`instance = new Singleton();`

这条语句实际上包含了三个操作：1.分配对象的内存空间；2.初始化对象；3.设置instance指向刚分配的内存地址。

但由于存在重排序的问题，可能有以下的执行顺序：

![image-20211229225451941](F:\WorkSpace\Lian\notes\面试\多线程面试.assets\image-20211229225451941.png)如果2和3进行了重排序的话，线程B进行判断if(instance==null)时就会为true，而实际上这个instance并没有初始化成功，显而易见对线程B来说之后的操作就会是错得。而用volatile修饰的话就可以禁止2和3操作重排序，从而避免这种情况。

**volatile包含禁止指令重排序的语义，其具有有序性。**

# Java并发和并行

并发 : 是指两个或多个事件在**同一时间间隔**发生,在一台处理器上“同时”处理多个任务;

并行 : 是指两个或者多个事件在**同一时刻**发生,在多台处理器上同时处理多个任务。



# 高并发解决方案——提升高并发量服务器性能解决思路

## 1、HTML静态化

## 2、图片服务器分离

## 3、数据库集群、库表散列

MySQL提供的Master/Slave

## 4、缓存

## 5、镜像

## 6、负载均衡

### （1）、硬件四层交换

### （2）、软件四层交换

### 7、最新：CDN加速技术

。。。。。。



# 大型网站是怎样解决多用户高并发访问的

分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。

集群主要分为：**高可用集群(High Availability Cluster)，负载均衡集群(Load Balance Cluster，nginx即可实现)，科学计算集群(High Performance Computing Cluster)**。

分布式是指将不同的业务分布在不同的地方；而集群指的是将几台服务器集中在一起，实现同一业务。

分布式中的每一个节点，都可以做集群。 而集群并不一定就是分布式的。



# Java阻塞队列--ArrayBlockingQueue和LinkedBlockingQueue实现原理分析

。。。。。。



# 线程的几种状态

线程在一定条件下，状态会发生变化。线程一共有以下几种状态：

1. 新建状态(New)：新创建了一个线程对象。
2. 就绪状态(Runnable)：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于
“可运行线程池”中，变得可运行，只等待获取CPU的使用权。即在就绪状态的进程除CPU之外，其
它的运行所需资源都已全部获得。
3. 运行状态(Running)：就绪状态的线程获取了CPU，执行程序代码。
4. 阻塞状态(Blocked)：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入
    就绪状态，才有机会转到运行状态。
    阻塞的情况分三种：
  1. 等待阻塞：运行的线程执行wait()方法，该线程会释放占用的所有资源，JVM会把该线程放入

    “等待池”中。进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或
    notifyAll()方法才能被唤醒，
  2. 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线

    程放入“锁池”中。
  3. 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为

    阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新
    转入就绪状态。
5. 死亡状态(Dead)：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

# java线程池与五种常用线程池策略使用与解析

## 一.线程池

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
}
```

其中各个参数含义如下：
**corePoolSize**- 池中所保存的线程数，包括空闲线程。需要注意的是在初创建线程池时线程不会立即
启动，直到有任务提交才开始启动线程并逐渐时线程数目达到corePoolSize。若想一开始就创建所有核
心线程需调用prestartAllCoreThreads方法。

**maximumPoolSize**-池中允许的最大线程数。需要注意的是当核心线程满且阻塞队列也满时才会判断
当前线程数是否小于最大线程数，并决定是否创建新线程。

**keepAliveTime** - 当线程数大于核心时，多于的空闲线程最多存活时间

**unit** - keepAliveTime 参数的时间单位。

**workQueue** - 当线程数目超过核心线程数时用于保存任务的队列。主要有3种类型的BlockingQueue可供选择：无界队列，有界队列和同步移交。将在下文中详细阐述。从参数中可以看到，此队列仅保存实现Runnable接口的任务。

**threadFactory** - 执行程序创建新线程时使用的工厂。

**handler** - 阻塞队列已满且线程数达到最大值时所采取的饱和策略。java默认提供了4种饱和策略的实现方式：中止、抛弃、抛弃最旧的、调用者运行。将在下文中详细阐述。

## 二、可选择的阻塞队列BlockingQueue详解

### 2.1 无界队列

队列大小无限制，常用的为无界的LinkedBlockingQueue，使用该队列做为阻塞队列时要尤其当心，当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM。最近工作中就遇到因为采用LinkedBlockingQueue作为阻塞队列，部分任务耗时80s＋且不停有新任务进来，导致cpu和内存飙升服务器挂掉。

### 2.2 有界队列

常用的有两类，一类是遵循FIFO原则的队列如ArrayBlockingQueue与有界的LinkedBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量。

### 2.3 同步移交

如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。**只有在使用无界线程池或者有饱和策略时才建议使用该队列。**



# 线程间通信，wait和notify

## 对于wait()和notify()的理解

- wait( )，notify( )，notifyAll( )都不属于Thread类，而是属于Object基础类，也就是每个对象都有wait( )，notify( )，notifyAll( ) 的功能，因为每个对象都有锁，锁是每个对象的基础，当然操作锁的方法也是最基础了。
- 当需要调用以上的方法的时候，一定要对竞争资源进行加锁，如果不加锁的话，则会报`IllegalMonitorStateException `异常
- 当想要调用wait( )进行线程等待时，必须要取得这个锁对象的控制权（对象监视器），一般是放到`synchronized(obj)`代码中。
- 在while循环里而不是if语句下使用wait，这样，会在线程暂停恢复后都检查wait的条件，并在条件
  实际上并未改变的情况下处理唤醒通知
- 调用obj.wait( )释放了obj的锁，否则其他线程也无法获得obj的锁，也就无法在`synchronized(obj){obj.notify() } `代码段内唤醒A。
- `notify( )`方法只会通知等待队列中的第一个相关线程（不会通知优先级比较高的线程）
- `notifyAll( )`通知所有等待该竞争资源的线程（也不会按照线程的优先级来执行）
- 假设有三个线程执行了obj.wait( )，那么obj.notifyAll( )则能全部唤醒tread1，thread2，
  thread3，但是要继续执行obj.wait（）的下一条语句，必须获得obj锁，因此，tread1，thread2，thread3只有一个有机会获得锁继续执行，例如tread1，其余的需要等待thread1释放obj锁之后才能继续执行。
- 当调用`obj.notify/notifyAll`后，调用线程依旧持有obj锁，因此，thread1，thread2，thread3虽被
  唤醒，但是仍无法获得obj锁。直到调用线程退出synchronized块，释放obj锁后，thread1，
  thread2，thread3中的一个才有机会获得锁继续执行。

## 示例

```java
package thread;

public class WaitNotifyTest {
    // 在多线程间共享的对象上使用wait
    private String[] shareObj = {"true"};

    public static void main(String[] args) {
        WaitNotifyTest test = new WaitNotifyTest();
        ThreadWait threadWait1 = test.new ThreadWait("wait thread1");
        threadWait1.setPriority(2);
        ThreadWait threadWait2 = test.new ThreadWait("wait thread2");
        threadWait2.setPriority(3);
        ThreadWait threadWait3 = test.new ThreadWait("wait thread3");
        threadWait3.setPriority(4);
        ThreadNotify threadNotify = test.new ThreadNotify("notify thread");
        threadNotify.start();
        threadWait1.start();
        threadWait2.start();
        threadWait3.start();
    }

    class ThreadWait extends Thread {
        public ThreadWait(String name) {
            super(name);
        }

        public void run() {
            synchronized (shareObj) {
                while ("true".equals(shareObj[0])) {
                    System.out.println("线程" + this.getName() + "开始等待");
                    long startTime = System.currentTimeMillis();
                    try {
                        shareObj.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    long endTime = System.currentTimeMillis();
                    System.out.println("线程" + this.getName()
                            + "等待时间为：" + (endTime - startTime));
                }
            }
            System.out.println("线程" + getName() + "等待结束");
        }
    }

    class ThreadNotify extends Thread {
        public ThreadNotify(String name) {
            super(name);
        }

        public void run() {
            try {
                // 给等待线程等待时间
                sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            synchronized (shareObj) {
                System.out.println("线程" + this.getName() + "开始准备通知");
                shareObj[0] = "false";
                shareObj.notifyAll();
                System.out.println("线程" + this.getName() + "通知结束");
            }
            System.out.println("线程" + this.getName() + "运行结束");
        }
    }
}


```

# java线程池主线程等待子线程执行完成

1、Thread 类给我们提供了join 系列的方法, 这些方法的目的就是等待当前线程的die.

2、使用并发包下面的Future模式。Future是一个任务执行的结果, 他是一个将来时, 即一个任务执行, 立即异步返回一个Future对象, 等到任务结束的时候, 会把值返回给这个future对象里面. 我们可以使用ExecutorService接口来提交一个线程.

3、CountDownLanch 是一个倒数计数器, 给一个初始值(>=0), 然后没countDown一次就会减1, 这很符合等待多个子线程结束的产景: 一个线程结束的时候, countDown一次, 直到所有都countDown了 , 那么所有子线程就都结束了。我们只需要在子线程执行之前, 赋予初始化countDownLanch, 并赋予线程数量为初始值.每个线程执行完毕的时候, 就countDown一下.主线程只需要调用await方法, 可以等待所有子线程执行结束
